diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 47fe936ce8c9e853bac03f59c682b40efeab0799..09c1ed845b7c491a1d3ee32f9c04a09650776017 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -2,41 +2,69 @@ name: ci
 
 on:
   push:
   pull_request:
 
 jobs:
   build:
     runs-on: ubuntu-latest
     steps:
       - uses: actions/checkout@v4
 
       - name: Setup Node.js
         uses: actions/setup-node@v4
         with:
           node-version: '20'
 
       - name: Install JS deps
         run: npm ci
 
       - name: Compile schemas
         run: npm run schema:compile
 
       - name: Run compose on examples
         run: npm run compose
 
+      - name: Composer duplicate provider failure
+        run: |
+          rm -rf ./tmp/dup-fail
+          if node tm.mjs compose --compose ./examples/dup-provider/compose.fail.json --modules-root ./examples/modules --out ./tmp/dup-fail; then
+            echo "expected tm compose to fail with E_DUP_PROVIDER" >&2
+            exit 1
+          fi
+
+      - name: Composer duplicate provider resolution
+        run: |
+          rm -rf ./examples/dup-provider/winner
+          node tm.mjs compose \
+            --compose ./examples/dup-provider/compose.ok.json \
+            --modules-root ./examples/modules \
+            --out ./examples/dup-provider/winner \
+            --explain
+
       - name: Compose examples → winner workspace
         run: node runtimes/ts/composer/index.mjs --compose ./examples/compose.json --modules-root ./examples/modules --glue-root ./glue-catalog --out ./examples/winner
 
       - name: Gates (shipping) on modules
         run: node tm.mjs gates shipping --compose ./examples/compose.json --modules-root ./examples/modules
 
       - name: Gates (shipping) on winner with events
-        run: node tm.mjs gates shipping --compose ./examples/compose.json --modules-root ./examples/winner/modules --emit-events --hook-cmd "node scripts/echo-hook.mjs"
+        run: |
+          mkdir -p artifacts
+          node tm.mjs gates shipping \
+            --compose ./examples/compose.json \
+            --modules-root ./examples/winner/modules \
+            --emit-events \
+            --events-out artifacts/events.ndjson \
+            --strict-events \
+            --hook-cmd "node scripts/echo-hook.mjs"
+
+      - name: Validate gate events
+        run: node scripts/validate-events.mjs artifacts/events.ndjson
 
       - name: Setup Rust
         uses: dtolnay/rust-toolchain@stable
 
       - name: Cargo check (ports/composer)
         run: |
           cd runtimes/rust/ports && cargo check
           cd ../composer && cargo check
diff --git a/.gitignore b/.gitignore
index 12ebd6aa521d806a1e2a06415652ded173a2cb85..95629e86e9821580ad9e288628b50316fe9d2d4f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,22 +1,24 @@
 # Node
 node_modules
 npm-debug.log*
 pnpm-lock.yaml
 yarn.lock
 dist
 examples/winner/modules
 examples/winner/glue
 examples/winner/package.json
 examples/winner/ports.map.json
 examples/winner/tsconfig.json
 **/.tm/
 
 # Rust
 target
 **/*.rs.bk
 
 # Misc
 .DS_Store
 .idea
 .vscode
 .env
+artifacts/
+tmp/
diff --git a/README.md b/README.md
index b68679fedff253f5c7c1d113660885874c573388..22501af2c93f4b40faefb4d1b4f0ec811f9c551b 100644
--- a/README.md
+++ b/README.md
@@ -5,61 +5,64 @@ Ports, specs, composer, and scaffolds for the **True Modules** approach — buil
 ## Quick start
 
 **Requirements:** Node.js ≥18, npm (or pnpm/yarn), optional Rust toolchain (stable).
 
 ```bash
 # 1) Install JS deps
 npm ci
 
 # 2) Compile schemas (AJV 2020-12)
 npm run schema:compile
 
 # 3) Try the example composition (uses ./examples)
 npm run compose
 
 # 4) (Optional) Rust crates sanity-check
 cd runtimes/rust/ports && cargo check && cd ../composer && cargo check
 ```
 
 ## CLI (scaffold level)
 This repo provides a minimal CLI `tm` for schema validation and a basic composition flow:
 
 ```bash
 # Greedy meta selection (from coverage.json) → compose.json (uses risk/evidence scoring)
 node tm.mjs meta --coverage ./examples/coverage.json --out ./examples/compose.greedy.json
 
-# Compose (validate compose.json + module manifests) → winner artifacts
-node tm.mjs compose --compose ./examples/compose.json --modules-root ./examples/modules --out ./examples/winner
+# Compose (validate compose.json + module manifests) → winner artifacts + provider explain
+node tm.mjs compose --compose ./examples/compose.json --modules-root ./examples/modules --out ./examples/winner --explain
 
 # Conceptual/Shipping gates (light checks + cross-import lint)
 node tm.mjs gates conceptual --compose ./examples/compose.json --modules-root ./examples/modules
-node tm.mjs gates shipping   --compose ./examples/compose.json --modules-root ./examples/modules
-
-# Emit BO4 events + hook summary
+mkdir -p artifacts
 node tm.mjs gates shipping \
   --compose ./examples/compose.json \
   --modules-root ./examples/modules \
   --emit-events \
+  --events-out artifacts/events.ndjson \
+  --strict-events \
   --hook-cmd "node scripts/echo-hook.mjs"
 ```
 
 > **Note:** This is a scaffold: the CLI enforces schemas and basic wiring checks; it does not build or link code. The full Composer, Meta solver, and multi-runtime ports live in `/runtimes` as you evolve them.
 
 ## Scaffolding a new module
 
 ```bash
 node tm.mjs module --new safety.validation
 # creates ./modules/safety.validation with module.json, src/, tests/
 
 # Materialize winner workspace
 node runtimes/ts/composer/index.mjs \
   --compose ./examples/compose.json \
   --modules-root ./examples/modules \
   --glue-root ./glue-catalog \
   --out ./examples/winner
 ```
 
 See **[End-to-end swimlane](docs/swimlane.md)** for BO4 roles & hand-offs.
 Shipping test expectations live in **[docs/tests.md](docs/tests.md)**.
+Deterministic provider selection and compose diagnostics are covered in
+**[docs/composer.md](docs/composer.md)**. Event streaming semantics live in
+**[docs/events.md](docs/events.md)**.
 
 ## License
 Dual-licensed under **MIT** and **Apache-2.0**. See `LICENSE-MIT` and `LICENSE-APACHE`.
diff --git a/docs/composer.md b/docs/composer.md
new file mode 100644
index 0000000000000000000000000000000000000000..b7aa6802ea574dbf4110b2c1fdc4a98453c902f5
--- /dev/null
+++ b/docs/composer.md
@@ -0,0 +1,65 @@
+# Composer Duplicate Provider Policy
+
+The scaffold composer refuses plans that select multiple modules for the same
+port major unless the plan disambiguates the winner. Provider identity is
+normalized to `PortName@major`, so `DiffPort@1.2` and `DiffPort@1` are treated as
+`DiffPort@1` when evaluating conflicts.
+
+## Failure scenario
+
+If two modules both provide the same port major and the compose plan omits both
+explicit wiring and preferences, `tm compose` aborts with `E_DUP_PROVIDER`:
+
+```
+E_DUP_PROVIDER Duplicate providers for DiffPort@1: git.diff.alt, git.diff.core.
+Add wiring from orchestrator or constraint prefer:DiffPort@1=git.diff.alt.
+```
+
+The same policy is enforced by the TypeScript MVP composer under
+`runtimes/ts/composer`.
+
+## Resolving conflicts
+
+You can disambiguate by wiring the orchestrator to the desired provider:
+
+```jsonc
+{
+  "wiring": [
+    { "from": "git.diff.core:DiffPort", "to": "orchestrator:DiffPort" }
+  ]
+}
+```
+
+Alternatively, add a constraint declaring the preferred provider. Both string
+and structured forms are supported:
+
+```jsonc
+{
+  "constraints": [
+    "prefer:DiffPort@1=git.diff.core",
+    { "preferred_providers": { "DiffPort@1": "git.diff.core" } }
+  ]
+}
+```
+
+Preferences that target ports absent from the plan exit with `E_PREFER_UNSAT`.
+When a preference wins but other modules still provide the port, the composer
+emits a warning so you can clean up unused modules.
+
+## Explain output
+
+Run `tm compose --explain` to see the deterministic resolution for every port:
+
+```json
+[
+  {
+    "port": "DiffPort@1",
+    "provider": "git.diff.core",
+    "reason": "wired",
+    "candidates": ["git.diff.alt", "git.diff.core"]
+  }
+]
+```
+
+`reason` is `wired`, `preferred`, or `sole`, indicating whether the provider was
+chosen by wiring, by preference, or because it was the only option.
diff --git a/docs/events.md b/docs/events.md
new file mode 100644
index 0000000000000000000000000000000000000000..9d84ebc9e4aa8aff56b024f084745179ac137632
--- /dev/null
+++ b/docs/events.md
@@ -0,0 +1,64 @@
+# Gate Event Stream (`tm-events@1`)
+
+Shipping automation relies on a structured telemetry stream emitted by
+`tm gates`. When `--emit-events` is enabled the CLI writes line-delimited JSON to
+stdout and (optionally) to a file sink via `--events-out`.
+
+Each event conforms to `spec/events.schema.json` and carries a common envelope:
+
+```json
+{
+  "schema": "tm-events@1",
+  "event": "TEST_PASS",
+  "ts": "2024-06-22T17:05:13.102Z",
+  "seq": 12,
+  "source": { "cli": "tm", "version": "0.1.0" },
+  "context": {
+    "run_id": "demo-run",
+    "mode": "shipping",
+    "compose_sha256": "3a6ce7..."
+  },
+  "detail": {
+    "module": "git.diff.core",
+    "test": "script:tests/run.mjs",
+    "dur_ms": 942
+  }
+}
+```
+
+Events are emitted in a single monotonic sequence. Typical envelopes include:
+
+- `GATES_START`/`GATES_PASS`/`GATES_FAIL` summarising the run (with `dur_ms`,
+  `passed`, `failed`, and `code` when errors occur).
+- `LINT_*`, `TEST_*`, and `TSC_*` capturing lint/test/type-check progress with
+  durations and failure codes (`E_LINT`, `E_TEST`, `E_TSC`).
+- `PORT_CHECK_*` tracing TypeScript harness generation for runtime ports.
+
+## Strict validation
+
+Use `--strict-events` to enforce schema compliance at emit-time. Violations
+immediately abort the run with `E_EVENT_SCHEMA` so the pipeline never records
+invalid telemetry. CI enables strict mode and validates the resulting NDJSON
+artifact against `spec/events.schema.json`.
+
+When strict mode is disabled (`--no-strict-events`), events are still emitted but
+schema failures are ignored—handy for interactive debugging.
+
+## File sink
+
+`--events-out <file>` records the same NDJSON stream to disk. The file is
+appended by default; add `--events-truncate` to overwrite instead. Directories
+are created automatically, making it easy to stash events under `artifacts/`:
+
+```bash
+mkdir -p artifacts
+node tm.mjs gates shipping \
+  --compose compose.json \
+  --modules-root modules \
+  --emit-events \
+  --events-out artifacts/events.ndjson \
+  --strict-events
+```
+
+Each event may include an `artifact` pointer (for example the TypeScript log) so
+automation can upload supporting evidence alongside the NDJSON file.
diff --git a/examples/dup-provider/compose.fail.json b/examples/dup-provider/compose.fail.json
new file mode 100644
index 0000000000000000000000000000000000000000..837f11ff5c1a28966fdc94be855f37c871a23ff6
--- /dev/null
+++ b/examples/dup-provider/compose.fail.json
@@ -0,0 +1,15 @@
+{
+  "run_id": "dup-provider-fail",
+  "modules": [
+    { "id": "git.diff.core", "version": "0.1.0" },
+    { "id": "git.diff.alt", "version": "0.1.0" },
+    { "id": "safety.validation", "version": "0.1.0" }
+  ],
+  "wiring": [
+    { "from": "safety.validation:SafetyPort", "to": "git.diff.core:SafetyPort" }
+  ],
+  "constraints": [
+    "no-cross-imports",
+    "ports-only-coupling"
+  ]
+}
diff --git a/examples/dup-provider/compose.ok.json b/examples/dup-provider/compose.ok.json
new file mode 100644
index 0000000000000000000000000000000000000000..e3892d1837eba9742cb72c17669937fd86987f10
--- /dev/null
+++ b/examples/dup-provider/compose.ok.json
@@ -0,0 +1,16 @@
+{
+  "run_id": "dup-provider-ok",
+  "modules": [
+    { "id": "git.diff.core", "version": "0.1.0" },
+    { "id": "git.diff.alt", "version": "0.1.0" },
+    { "id": "safety.validation", "version": "0.1.0" }
+  ],
+  "wiring": [
+    { "from": "safety.validation:SafetyPort", "to": "git.diff.core:SafetyPort" }
+  ],
+  "constraints": [
+    "no-cross-imports",
+    "ports-only-coupling",
+    { "preferred_providers": { "DiffPort@1": "git.diff.core" } }
+  ]
+}
diff --git a/examples/modules/git.diff.alt/module.json b/examples/modules/git.diff.alt/module.json
new file mode 100644
index 0000000000000000000000000000000000000000..17c6a80a3764283495f3958ad0da4824ef57295a
--- /dev/null
+++ b/examples/modules/git.diff.alt/module.json
@@ -0,0 +1,36 @@
+{
+  "id": "git.diff.alt",
+  "version": "0.1.0",
+  "summary": "Alternative diff provider for duplicate-provider fixtures",
+  "provides": [
+    "DiffPort@1"
+  ],
+  "requires": [
+    "SafetyPort@1"
+  ],
+  "inputs": {},
+  "outputs": {},
+  "side_effects": [
+    "Process:git",
+    "FS:read"
+  ],
+  "invariants": [
+    "deterministic(outputs | inputs)",
+    "conserves: no write outside worktree"
+  ],
+  "tests": [
+    "tests/spec_diff_tracked.json",
+    "tests/spec_diff_untracked.json"
+  ],
+  "port_exports": {
+    "DiffPort@1": { "file": "src/index.ts", "export": "diffPort" }
+  },
+  "evidence": [
+    {
+      "kind": "file",
+      "file": "src/lib.rs",
+      "lines": "1-40",
+      "note": "example placeholder"
+    }
+  ]
+}
diff --git a/examples/modules/git.diff.alt/src/index.ts b/examples/modules/git.diff.alt/src/index.ts
new file mode 100644
index 0000000000000000000000000000000000000000..a5a190677f9df1b1e94dc383e7719af611d5dd02
--- /dev/null
+++ b/examples/modules/git.diff.alt/src/index.ts
@@ -0,0 +1,8 @@
+type DiffSpec = { paths: string[] };
+type DiffResult = { summary: string };
+
+export const diffPort = {
+  async diff(_spec: DiffSpec): Promise<DiffResult> {
+    return { summary: 'stub diff' };
+  }
+};
diff --git a/examples/modules/git.diff.alt/src/lib.rs b/examples/modules/git.diff.alt/src/lib.rs
new file mode 100644
index 0000000000000000000000000000000000000000..329f22173fe78d20e50a958b94def3434b4a8dd9
--- /dev/null
+++ b/examples/modules/git.diff.alt/src/lib.rs
@@ -0,0 +1 @@
+// placeholder
\ No newline at end of file
diff --git a/examples/modules/git.diff.alt/tests/runner.mjs b/examples/modules/git.diff.alt/tests/runner.mjs
new file mode 100644
index 0000000000000000000000000000000000000000..a3e8096d9aceea2640b86ed5de06b80cdec89c14
--- /dev/null
+++ b/examples/modules/git.diff.alt/tests/runner.mjs
@@ -0,0 +1,33 @@
+#!/usr/bin/env node
+import fs from 'fs/promises';
+import process from 'process';
+import path from 'path';
+
+const args = new Map(
+  process.argv.slice(2).map((value, idx, arr) => {
+    if (!value.startsWith('--')) return null;
+    return [value.replace(/^--/, ''), arr[idx + 1]];
+  }).filter(Boolean)
+);
+
+const specArg = args.get('spec');
+if (!specArg) {
+  console.error('Missing --spec argument');
+  process.exit(1);
+}
+
+const moduleRoot = args.get('moduleRoot');
+if (!moduleRoot) {
+  console.error('Missing --moduleRoot argument');
+  process.exit(1);
+}
+
+const specPath = path.isAbsolute(specArg) ? specArg : path.join(moduleRoot, specArg);
+const spec = JSON.parse(await fs.readFile(specPath, 'utf8'));
+
+if (!spec.name) {
+  console.error('Spec missing "name" field');
+  process.exit(1);
+}
+
+process.exit(0);
diff --git a/examples/modules/git.diff.alt/tests/spec_diff_tracked.json b/examples/modules/git.diff.alt/tests/spec_diff_tracked.json
new file mode 100644
index 0000000000000000000000000000000000000000..55053326c505690e1bf5a0530005d7fbd5c96857
--- /dev/null
+++ b/examples/modules/git.diff.alt/tests/spec_diff_tracked.json
@@ -0,0 +1 @@
+{"name":"tracked"}
\ No newline at end of file
diff --git a/examples/modules/git.diff.alt/tests/spec_diff_untracked.json b/examples/modules/git.diff.alt/tests/spec_diff_untracked.json
new file mode 100644
index 0000000000000000000000000000000000000000..61fa637d0ea68ee4990933f2d8e9809e7ef4254c
--- /dev/null
+++ b/examples/modules/git.diff.alt/tests/spec_diff_untracked.json
@@ -0,0 +1 @@
+{"name":"untracked"}
\ No newline at end of file
diff --git a/runtimes/ts/composer/index.mjs b/runtimes/ts/composer/index.mjs
index 7369d288d674df1c89dd646c61881bf78008bf0a..b86c0b75a1a89987a5e7888a7733b58fa58ae618 100644
--- a/runtimes/ts/composer/index.mjs
+++ b/runtimes/ts/composer/index.mjs
@@ -19,93 +19,246 @@ const glueRoot = path.resolve(args.get('glue-root') || './glue-catalog');
 const outDir = path.resolve(args.get('out') || './winner');
 
 async function readJSON(p) {
   const txt = await fs.readFile(p, 'utf8');
   return JSON.parse(txt);
 }
 
 function manifestPath(root, id) {
   return path.join(root, id, 'module.json');
 }
 
 async function copyDir(src, dst) {
   await fs.mkdir(dst, { recursive: true });
   if (fs.cp) {
     await fs.cp(src, dst, { recursive: true });
   } else {
     const { execSync } = await import('child_process');
     execSync(`cp -R "${src}/." "${dst}"`);
   }
 }
 
 function normalizePortName(entry) {
   return (entry || '').split('@')[0];
 }
 
+function tmError(code, message) {
+  const err = new Error(`${code} ${message}`);
+  err.code = code;
+  return err;
+}
+
+function parsePortId(portId) {
+  const [name, rawVersion] = String(portId || '').split('@');
+  const versionPart = rawVersion && rawVersion.length ? rawVersion : '1';
+  const major = versionPart.split('.')[0] || '1';
+  return { name, major };
+}
+
+function portMajorId(portId) {
+  const parsed = parsePortId(portId);
+  if (!parsed.name) {
+    throw tmError('E_COMPOSE', `Invalid port identifier: ${portId}`);
+  }
+  return `${parsed.name}@${parsed.major}`;
+}
+
+function extractPreferredProviders(constraints) {
+  const preferred = new Map();
+  for (const constraint of constraints || []) {
+    if (!constraint) continue;
+    if (typeof constraint === 'string') {
+      const match = /^prefer:([A-Za-z][A-Za-z0-9]*Port@\d+)=([a-z][a-z0-9_.-]+)$/.exec(constraint.trim());
+      if (match) {
+        const [, port, module] = match;
+        const prev = preferred.get(port);
+        if (prev && prev !== module) {
+          throw tmError('E_PREFER_UNSAT', `Conflicting preferred providers for ${port}: ${prev} vs ${module}`);
+        }
+        preferred.set(port, module);
+      }
+      continue;
+    }
+    if (typeof constraint === 'object' && !Array.isArray(constraint) && constraint.preferred_providers) {
+      for (const [port, module] of Object.entries(constraint.preferred_providers)) {
+        if (typeof module !== 'string') continue;
+        if (!/^[A-Za-z][A-Za-z0-9]*Port@\d+$/.test(port)) continue;
+        if (!/^[a-z][a-z0-9_.-]+$/.test(module)) continue;
+        const prev = preferred.get(port);
+        if (prev && prev !== module) {
+          throw tmError('E_PREFER_UNSAT', `Conflicting preferred providers for ${port}: ${prev} vs ${module}`);
+        }
+        preferred.set(port, module);
+      }
+    }
+  }
+  return preferred;
+}
+
+function analyzeProviders(compose, manifests) {
+  const infoMap = new Map();
+  const modulePortIndex = new Map();
+
+  for (const [moduleId, manifest] of Object.entries(manifests)) {
+    const portMap = new Map();
+    for (const portId of manifest.provides || []) {
+      const major = portMajorId(portId);
+      const name = normalizePortName(portId);
+      if (!infoMap.has(major)) {
+        infoMap.set(major, { port: major, providers: new Set(), chosen: null, reason: null });
+      }
+      infoMap.get(major).providers.add(moduleId);
+      if (!portMap.has(name)) portMap.set(name, []);
+      portMap.get(name).push(major);
+    }
+    modulePortIndex.set(moduleId, portMap);
+  }
+
+  const preferred = extractPreferredProviders(compose.constraints || []);
+  const moduleIds = new Set(Object.keys(manifests));
+
+  for (const [port, moduleId] of preferred.entries()) {
+    const info = infoMap.get(port);
+    if (!info) {
+      throw tmError('E_PREFER_UNSAT', `Preferred provider for ${port} not present in compose plan.`);
+    }
+    if (!moduleIds.has(moduleId) || !info.providers.has(moduleId)) {
+      throw tmError('E_PREFER_UNSAT', `Preferred provider ${moduleId} does not supply ${port}.`);
+    }
+  }
+
+  for (const wiring of compose.wiring || []) {
+    if (!wiring) continue;
+    const [fromModule, fromPort] = String(wiring.from || '').split(':');
+    const [toModule, toPort] = String(wiring.to || '').split(':');
+    if (!fromModule || !fromPort || !toModule || !toPort) continue;
+    let moduleId = null;
+    let portName = null;
+    if (fromModule !== 'orchestrator' && toModule === 'orchestrator') {
+      moduleId = fromModule;
+      portName = fromPort;
+    } else if (toModule !== 'orchestrator' && fromModule === 'orchestrator') {
+      moduleId = toModule;
+      portName = toPort;
+    } else {
+      continue;
+    }
+    if (!manifests[moduleId]) continue;
+    const candidates = (modulePortIndex.get(moduleId)?.get(portName)) || [];
+    if (candidates.length === 0) {
+      throw tmError('E_COMPOSE', `Module ${moduleId} does not provide port ${portName}`);
+    }
+    if (candidates.length > 1) {
+      throw tmError('E_COMPOSE', `Module ${moduleId} provides multiple majors for port ${portName}; add constraints to disambiguate.`);
+    }
+    const port = candidates[0];
+    const info = infoMap.get(port);
+    if (!info) continue;
+    if (info.chosen && info.chosen !== moduleId) {
+      throw tmError('E_DUP_PROVIDER', `Conflicting wiring for ${port}: ${info.chosen} vs ${moduleId}`);
+    }
+    info.chosen = moduleId;
+    info.reason = 'wired';
+  }
+
+  for (const [port, moduleId] of preferred.entries()) {
+    const info = infoMap.get(port);
+    if (!info) continue;
+    if (info.reason === 'wired') {
+      if (info.chosen !== moduleId) {
+        console.warn(`Preference for ${port}=${moduleId} ignored because wiring selected ${info.chosen}.`);
+      }
+      continue;
+    }
+    info.chosen = moduleId;
+    info.reason = 'preferred';
+  }
+
+  const unresolved = [];
+  for (const info of infoMap.values()) {
+    info.providers = Array.from(info.providers).sort();
+    if (!info.chosen) {
+      if (info.providers.length === 1) {
+        info.chosen = info.providers[0];
+        info.reason = 'sole';
+      } else if (info.providers.length > 1) {
+        unresolved.push(info);
+      }
+    }
+  }
+
+  if (unresolved.length) {
+    const target = unresolved.sort((a, b) => a.port.localeCompare(b.port))[0];
+    const msg = `Duplicate providers for ${target.port}: ${target.providers.join(', ')}.\nAdd wiring from orchestrator or constraint prefer:${target.port}=${target.providers[0]}.`;
+    throw tmError('E_DUP_PROVIDER', msg);
+  }
+
+  for (const info of infoMap.values()) {
+    if (info.reason === 'preferred' && info.providers.length > 1) {
+      const leftovers = info.providers.filter(p => p !== info.chosen);
+      if (leftovers.length) {
+        console.warn(`Preferred provider for ${info.port} selected ${info.chosen}; remaining providers: ${leftovers.join(', ')}`);
+      }
+    }
+  }
+}
+
 (async () => {
   const compose = await readJSON(composePath);
   await fs.mkdir(outDir, { recursive: true });
 
   // Load manifests
   const manifById = {};
   for (const mod of compose.modules || []) {
     const mp = manifestPath(modulesRoot, mod.id);
     manifById[mod.id] = await readJSON(mp);
   }
 
-  // Duplicate providers check
+  analyzeProviders(compose, manifById);
+
   const providers = {};
   for (const [id, man] of Object.entries(manifById)) {
     for (const p of (man.provides || [])) {
       const name = normalizePortName(p);
       if (!providers[name]) providers[name] = [];
       providers[name].push(id);
     }
   }
 
-  const duplicateProviders = Object.entries(providers).filter(([, ids]) => ids.length > 1);
-  const hasExplicitWiring = Array.isArray(compose.wiring) && compose.wiring.length > 0;
-  if (duplicateProviders.length && !hasExplicitWiring) {
-    const msg = duplicateProviders
-      .map(([port, ids]) => `  ${port}: ${ids.join(', ')}`)
-      .join('\n');
-    throw new Error('Multiple modules provide the same port without explicit wiring:\n' + msg);
-  }
-
   // Requires check
   const providedPorts = new Set(Object.keys(providers));
   const reqProblems = [];
   for (const [id, man] of Object.entries(manifById)) {
     for (const req of (man.requires || [])) {
       const name = normalizePortName(req);
       if (!providedPorts.has(name)) {
         reqProblems.push(`${id} requires ${req} but no selected module provides ${name}`);
       }
     }
   }
   if (reqProblems.length) {
-    throw new Error('Port requires unsatisfied:\n' + reqProblems.join('\n'));
+    throw tmError('E_REQUIRE_UNSAT', 'Port requires unsatisfied:\n' + reqProblems.join('\n'));
   }
 
   const winnerModulesDir = path.join(outDir, 'modules');
   await fs.mkdir(winnerModulesDir, { recursive: true });
   for (const mod of compose.modules || []) {
     await copyDir(path.join(modulesRoot, mod.id), path.join(winnerModulesDir, mod.id));
   }
 
   const winnerGlueDir = path.join(outDir, 'glue');
   await fs.mkdir(winnerGlueDir, { recursive: true });
   for (const glue of compose.glue || []) {
     if (!glue || !glue.id) continue;
     await copyDir(path.join(glueRoot, glue.id), path.join(winnerGlueDir, glue.id));
   }
 
   const portsMap = Object.fromEntries(Object.entries(providers).map(([port, ids]) => [port, ids]));
   await fs.writeFile(path.join(outDir, 'ports.map.json'), JSON.stringify(portsMap, null, 2));
 
   const report = {
     context: {
       run_id: compose.run_id || new Date().toISOString(),
       composer: 'ts-composer@0.1',
       generated_at: new Date().toISOString()
     },
     bill_of_materials: (compose.modules || []).map(m => ({
diff --git a/scripts/validate-events.mjs b/scripts/validate-events.mjs
new file mode 100755
index 0000000000000000000000000000000000000000..b666d4b8221bd1c375b020905370b78ea411918c
--- /dev/null
+++ b/scripts/validate-events.mjs
@@ -0,0 +1,51 @@
+#!/usr/bin/env node
+import fs from 'fs/promises';
+import path from 'path';
+import { fileURLToPath } from 'url';
+import Ajv2020 from 'ajv/dist/2020.js';
+import addFormats from 'ajv-formats';
+
+const __filename = fileURLToPath(import.meta.url);
+const __dirname = path.dirname(__filename);
+
+const targetFile = process.argv[2];
+if (!targetFile) {
+  console.error('Usage: node scripts/validate-events.mjs <events.ndjson>');
+  process.exit(1);
+}
+
+const specDir = path.resolve(__dirname, '..', 'spec');
+
+async function loadSchema() {
+  const schemaPath = path.join(specDir, 'events.schema.json');
+  const txt = await fs.readFile(schemaPath, 'utf8');
+  return JSON.parse(txt);
+}
+
+(async () => {
+  const schema = await loadSchema();
+  const ajv = new Ajv2020({ allErrors: true, strict: false });
+  addFormats(ajv);
+  const validate = ajv.compile(schema);
+
+  const buf = await fs.readFile(path.resolve(targetFile), 'utf8');
+  const lines = buf.split(/\r?\n/).filter(Boolean);
+  for (let i = 0; i < lines.length; i++) {
+    let parsed;
+    try {
+      parsed = JSON.parse(lines[i]);
+    } catch (err) {
+      console.error(`Line ${i + 1}: invalid JSON - ${err.message}`);
+      process.exit(1);
+    }
+    const ok = validate(parsed);
+    if (!ok) {
+      const message = (validate.errors || [])
+        .map(e => `${e.instancePath} ${e.message}`)
+        .join('; ');
+      console.error(`Line ${i + 1}: schema violation - ${message}`);
+      process.exit(1);
+    }
+  }
+  console.log(`✓ ${lines.length} events validated against tm-events@1`);
+})();
diff --git a/spec/compose.schema.json b/spec/compose.schema.json
index cd09fc360d230a9a164a723c202843ebe7341e53..4643e75efe0cb8855999c70ac8b58a9422b85d95 100644
--- a/spec/compose.schema.json
+++ b/spec/compose.schema.json
@@ -65,30 +65,48 @@
           "version"
         ],
         "additionalProperties": false,
         "properties": {
           "id": {
             "type": "string",
             "pattern": "^[a-z][a-z0-9_.-]+$"
           },
           "from": {
             "type": "string",
             "pattern": "^[A-Za-z][A-Za-z0-9]*$"
           },
           "to": {
             "type": "string",
             "pattern": "^[A-Za-z][A-Za-z0-9]*$"
           },
           "version": {
             "type": "string"
           }
         }
       }
     },
     "constraints": {
       "type": "array",
       "items": {
-        "type": "string"
+        "oneOf": [
+          { "type": "string" },
+          {
+            "type": "object",
+            "additionalProperties": false,
+            "properties": {
+              "preferred_providers": {
+                "type": "object",
+                "propertyNames": {
+                  "pattern": "^[A-Za-z][A-Za-z0-9]*Port@\\d+$"
+                },
+                "additionalProperties": {
+                  "type": "string",
+                  "pattern": "^[a-z][a-z0-9_.-]+$"
+                }
+              }
+            }
+          }
+        ]
       }
     }
   }
 }
\ No newline at end of file
diff --git a/spec/events.schema.json b/spec/events.schema.json
new file mode 100644
index 0000000000000000000000000000000000000000..fe47df23d0ccff80e02e9b5059b1e7084634f265
--- /dev/null
+++ b/spec/events.schema.json
@@ -0,0 +1,74 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://true-modules/spec/events.schema.json",
+  "title": "tm-events@1",
+  "type": "object",
+  "additionalProperties": false,
+  "required": ["schema", "event", "ts", "seq", "source", "context"],
+  "properties": {
+    "schema": { "const": "tm-events@1" },
+    "event": {
+      "type": "string",
+      "enum": [
+        "GATES_START",
+        "GATES_PASS",
+        "GATES_FAIL",
+        "GATES_WARN",
+        "TEST_START",
+        "TEST_PASS",
+        "TEST_FAIL",
+        "LINT_START",
+        "LINT_PASS",
+        "LINT_FAIL",
+        "TSC_START",
+        "TSC_PASS",
+        "TSC_FAIL",
+        "PORT_CHECK_START",
+        "PORT_CHECK_PASS",
+        "PORT_CHECK_FAIL"
+      ]
+    },
+    "ts": { "type": "string", "format": "date-time" },
+    "seq": { "type": "integer", "minimum": 1 },
+    "source": {
+      "type": "object",
+      "required": ["cli", "version"],
+      "additionalProperties": false,
+      "properties": {
+        "cli": { "type": "string" },
+        "version": { "type": "string" }
+      }
+    },
+    "context": {
+      "type": "object",
+      "required": ["run_id", "mode", "compose_sha256"],
+      "additionalProperties": false,
+      "properties": {
+        "run_id": { "type": "string" },
+        "mode": { "type": "string", "enum": ["conceptual", "shipping"] },
+        "compose_sha256": { "type": "string", "pattern": "^[0-9a-f]{64}$" }
+      }
+    },
+    "detail": {
+      "type": "object",
+      "additionalProperties": false,
+      "properties": {
+        "module": { "type": "string" },
+        "port": { "type": "string" },
+        "test": { "type": "string" },
+        "dur_ms": { "type": "number", "minimum": 0 },
+        "error": { "type": "string" },
+        "code": { "type": "string", "pattern": "^[A-Z0-9_]+$" },
+        "artifact": { "type": "string" },
+        "compose_path": { "type": "string" },
+        "modules_total": { "type": "integer", "minimum": 0 },
+        "message": { "type": "string" },
+        "lint_tool": { "type": "string" },
+        "file": { "type": "string" },
+        "line": { "type": "integer", "minimum": 0 },
+        "passed": { "type": "integer", "minimum": 0 },
+        "failed": { "type": "integer", "minimum": 0 }
+      }
+    }
+  }
+}
diff --git a/tm.mjs b/tm.mjs
index 20e7d3ca6c835720dbb7f31743f78c3401ed7817..3d2628e014b4189c62b47249682108e01df7bf2f 100644
--- a/tm.mjs
+++ b/tm.mjs
@@ -1,57 +1,255 @@
 #!/usr/bin/env node
 import { Command } from 'commander';
 import fs from 'fs/promises';
 import path from 'path';
 import { fileURLToPath } from 'url';
 import { createRequire } from 'module';
 import Ajv2020 from 'ajv/dist/2020.js';
 import addFormats from 'ajv-formats';
 import { spawn } from 'child_process';
+import crypto from 'crypto';
 import { collectCrossImportDiagnostics } from './scripts/eslint-run.mjs';
 
 const __filename = fileURLToPath(import.meta.url);
 const __dirname = path.dirname(__filename);
 
+const CLI_VERSION = '0.1.0';
 const program = new Command();
-program.name('tm').description('True Modules CLI (scaffold)').version('0.1.0');
+program.name('tm').description('True Modules CLI (scaffold)').version(CLI_VERSION);
 
 const specDir = path.join(__dirname, 'spec');
 
 async function loadJSON(p) {
   const txt = await fs.readFile(p, 'utf8');
   try { return JSON.parse(txt); } catch (e) {
     throw new Error(`Failed to parse JSON at ${p}: ${e.message}`);
   }
 }
 
 function makeAjv() {
   const ajv = new Ajv2020({ allErrors: true, strict: false });
   addFormats(ajv);
   return ajv;
 }
 
+function tmError(code, message) {
+  const err = new Error(`${code} ${message}`);
+  err.code = code;
+  return err;
+}
+
+function parsePortId(portId) {
+  const [name, rawVersion] = String(portId || '').split('@');
+  const versionPart = rawVersion && rawVersion.length ? rawVersion : '1';
+  const major = versionPart.split('.')[0] || '1';
+  return { name, version: versionPart, major };
+}
+
+function portMajorId(portId) {
+  const info = parsePortId(portId);
+  if (!info.name) throw tmError('E_COMPOSE', `Invalid port identifier: ${portId}`);
+  return `${info.name}@${info.major}`;
+}
+
+function portName(portId) {
+  return parsePortId(portId).name;
+}
+
+function parseWiringEndpoint(entry) {
+  const [module, port] = String(entry || '').split(':');
+  if (!module || !port) {
+    throw tmError('E_COMPOSE', `Invalid wiring endpoint: ${entry}`);
+  }
+  return { module, port };
+}
+
+function extractPreferredProviders(constraints) {
+  const preferred = new Map();
+  for (const constraint of constraints || []) {
+    if (!constraint) continue;
+    if (typeof constraint === 'string') {
+      const trimmed = constraint.trim();
+      const match = /^prefer:([A-Za-z][A-Za-z0-9]*Port@\d+)=([a-z][a-z0-9_.-]+)$/.exec(trimmed);
+      if (match) {
+        const [, port, module] = match;
+        const prev = preferred.get(port);
+        if (prev && prev !== module) {
+          throw tmError('E_PREFER_UNSAT', `Conflicting preferred providers for ${port}: ${prev} vs ${module}`);
+        }
+        preferred.set(port, module);
+      }
+      continue;
+    }
+    if (typeof constraint === 'object' && !Array.isArray(constraint)) {
+      if (constraint.preferred_providers && typeof constraint.preferred_providers === 'object') {
+        for (const [port, module] of Object.entries(constraint.preferred_providers)) {
+          if (typeof module !== 'string') continue;
+          if (!/^[A-Za-z][A-Za-z0-9]*Port@\d+$/.test(port)) continue;
+          if (!/^[a-z][a-z0-9_.-]+$/.test(module)) continue;
+          const prev = preferred.get(port);
+          if (prev && prev !== module) {
+            throw tmError('E_PREFER_UNSAT', `Conflicting preferred providers for ${port}: ${prev} vs ${module}`);
+          }
+          preferred.set(port, module);
+        }
+      }
+    }
+  }
+  return preferred;
+}
+
+function analyzeProviders(compose, moduleEntries) {
+  const infoMap = new Map();
+  const modulePortIndex = new Map();
+  const moduleIds = new Set(Object.keys(moduleEntries));
+
+  for (const [moduleId, entry] of Object.entries(moduleEntries)) {
+    const manifest = entry.manifest;
+    const provides = manifest.provides || [];
+    const portMap = new Map();
+    for (const portId of provides) {
+      const major = portMajorId(portId);
+      const name = portName(portId);
+      if (!infoMap.has(major)) {
+        infoMap.set(major, {
+          port: major,
+          providers: new Set(),
+          chosen: null,
+          reason: null
+        });
+      }
+      infoMap.get(major).providers.add(moduleId);
+      if (!portMap.has(name)) portMap.set(name, []);
+      portMap.get(name).push(major);
+    }
+    modulePortIndex.set(moduleId, portMap);
+  }
+
+  const preferred = extractPreferredProviders(compose.constraints || []);
+
+  for (const [port, moduleId] of preferred.entries()) {
+    if (!infoMap.has(port)) {
+      throw tmError('E_PREFER_UNSAT', `Preferred provider for ${port} not present in compose plan.`);
+    }
+    if (!moduleIds.has(moduleId)) {
+      throw tmError('E_PREFER_UNSAT', `Preferred provider ${moduleId} for ${port} is not part of the compose modules.`);
+    }
+    const info = infoMap.get(port);
+    if (!info.providers.has(moduleId)) {
+      throw tmError('E_PREFER_UNSAT', `Preferred provider ${moduleId} does not supply ${port}.`);
+    }
+  }
+
+  for (const w of compose.wiring || []) {
+    const from = parseWiringEndpoint(w.from);
+    const to = parseWiringEndpoint(w.to);
+    let moduleId = null;
+    let portKey = null;
+    if (from.module !== 'orchestrator' && to.module === 'orchestrator') {
+      moduleId = from.module;
+      portKey = from.port;
+    } else if (to.module !== 'orchestrator' && from.module === 'orchestrator') {
+      moduleId = to.module;
+      portKey = to.port;
+    } else {
+      continue;
+    }
+    if (!moduleEntries[moduleId]) continue;
+    const portMap = modulePortIndex.get(moduleId) || new Map();
+    const matches = portMap.get(portKey) || [];
+    if (matches.length === 0) {
+      throw tmError('E_COMPOSE', `Module ${moduleId} does not provide port ${portKey}`);
+    }
+    if (matches.length > 1) {
+      throw tmError('E_COMPOSE', `Module ${moduleId} provides multiple majors for port ${portKey}; wiring must disambiguate via constraints.`);
+    }
+    const major = matches[0];
+    const info = infoMap.get(major);
+    if (!info) continue;
+    if (info.chosen && info.chosen !== moduleId) {
+      throw tmError('E_DUP_PROVIDER', `Conflicting wiring for ${major}: ${info.chosen} vs ${moduleId}`);
+    }
+    info.chosen = moduleId;
+    info.reason = 'wired';
+  }
+
+  for (const [port, moduleId] of preferred.entries()) {
+    const info = infoMap.get(port);
+    if (!info) continue;
+    if (info.reason === 'wired') {
+      if (info.chosen !== moduleId) {
+        console.warn(`Preference for ${port}=${moduleId} ignored due to wiring selecting ${info.chosen}.`);
+      }
+      continue;
+    }
+    info.chosen = moduleId;
+    info.reason = 'preferred';
+  }
+
+  const unresolved = [];
+  for (const info of infoMap.values()) {
+    info.providers = Array.from(info.providers).sort();
+    if (!info.chosen) {
+      if (info.providers.length === 1) {
+        info.chosen = info.providers[0];
+        info.reason = 'sole';
+      } else if (info.providers.length > 1) {
+        unresolved.push(info);
+      }
+    }
+  }
+
+  if (unresolved.length > 0) {
+    const target = unresolved.sort((a, b) => a.port.localeCompare(b.port))[0];
+    const msg = `Duplicate providers for ${target.port}: ${target.providers.join(', ')}.\nAdd wiring from orchestrator or constraint prefer:${target.port}=${target.providers[0]}.`;
+    throw tmError('E_DUP_PROVIDER', msg);
+  }
+
+  const warnings = [];
+  const explanations = Array.from(infoMap.values())
+    .map(info => {
+      if (info.reason === 'preferred' && info.providers.length > 1) {
+        const leftovers = info.providers.filter(p => p !== info.chosen);
+        if (leftovers.length) {
+          const warning = `Preferred provider for ${info.port} selected ${info.chosen}; remaining providers: ${leftovers.join(', ')}`;
+          warnings.push(warning);
+          console.warn(warning);
+        }
+      }
+      return {
+        port: info.port,
+        provider: info.chosen,
+        reason: info.reason,
+        candidates: info.providers
+      };
+    })
+    .sort((a, b) => a.port.localeCompare(b.port));
+
+  return { explanations, warnings };
+}
+
 async function validateAgainst(schemaName, data) {
   const ajv = makeAjv();
   const schema = await loadJSON(path.join(specDir, schemaName));
   const validate = ajv.compile(schema);
   const valid = validate(data);
   if (!valid) {
     const errs = (validate.errors || []).map(e => `${e.instancePath} ${e.message}`).join('\n');
     throw new Error(`Validation failed for ${schemaName}:\n${errs}`);
   }
 }
 
 async function validateFile(schemaName, filePath) {
   const data = await loadJSON(filePath);
   await validateAgainst(schemaName, data);
   return data;
 }
 
 async function runCmd(cmd, args, opts = {}) {
   const timeoutMs = opts.timeoutMs ?? 60_000;
   return new Promise((resolve, reject) => {
     const child = spawn(cmd, args, {
       cwd: opts.cwd,
       stdio: ['ignore', 'pipe', 'pipe'],
       shell: false
     });
@@ -65,124 +263,178 @@ async function runCmd(cmd, args, opts = {}) {
     child.on('exit', code => {
       clearTimeout(timer);
       if (code === 0) resolve({ out, err });
       else reject(new Error(err || `Exit ${code}`));
     });
   });
 }
 
 function verifyPortRequires(compose, manifestsById) {
   const provided = new Set();
   for (const man of Object.values(manifestsById)) {
     for (const p of (man.provides || [])) provided.add(p.split('@')[0]);
   }
   const problems = [];
   for (const [id, man] of Object.entries(manifestsById)) {
     for (const req of (man.requires || [])) {
       const name = req.split('@')[0];
       if (!provided.has(name)) {
         problems.push(`${id} requires ${req} but no selected module provides ${name}`);
       }
     }
   }
   return problems;
 }
 
-function makeEventEmitter(opts) {
-  const emit = (type, payload = {}) => {
+async function makeEventEmitter(opts) {
+  const context = {
+    run_id: opts.context?.run_id ?? null,
+    mode: opts.context?.mode ?? null,
+    compose_sha256: opts.context?.compose_sha256 ?? null
+  };
+  const strict = Boolean(opts.strictEvents);
+  let validator = null;
+  if (strict) {
+    const schema = await loadJSON(path.join(specDir, 'events.schema.json'));
+    const ajv = makeAjv();
+    validator = ajv.compile(schema);
+  }
+
+  let fileHandle = null;
+  if (opts.eventsOut) {
+    const target = path.resolve(opts.eventsOut);
+    await fs.mkdir(path.dirname(target), { recursive: true });
+    fileHandle = await fs.open(target, opts.eventsTruncate ? 'w' : 'a');
+  }
+
+  let seq = 0;
+  const writeLine = async (line) => {
     if (opts.emitEvents) {
-      const evt = { event: type, ts: new Date().toISOString(), ...payload };
-      process.stdout.write(JSON.stringify(evt) + '\n');
+      process.stdout.write(line + '\n');
+    }
+    if (fileHandle) {
+      await fileHandle.appendFile(line + '\n');
     }
   };
+
+  const emit = async (event, detail = {}) => {
+    const envelope = {
+      schema: 'tm-events@1',
+      event,
+      ts: new Date().toISOString(),
+      seq: ++seq,
+      source: { cli: 'tm', version: CLI_VERSION },
+      context
+    };
+    if (detail && Object.keys(detail).length > 0) {
+      envelope.detail = detail;
+    }
+    if (validator) {
+      const valid = validator(envelope);
+      if (!valid) {
+        const errs = (validator.errors || []).map(e => `${e.instancePath} ${e.message}`).join('; ');
+        throw tmError('E_EVENT_SCHEMA', `Event ${event} failed validation: ${errs}`);
+      }
+    }
+    await writeLine(JSON.stringify(envelope));
+  };
+
   const info = (msg) => {
     (opts.emitEvents ? console.error : console.log)(msg);
   };
-  return { emit, info };
+
+  const close = async () => {
+    if (fileHandle) {
+      await fileHandle.close();
+      fileHandle = null;
+    }
+  };
+
+  return { emit, info, close };
 }
 
 function interfaceNameForPort(portId) {
   const [name, versionRaw] = (portId || '').split('@');
   const version = Number(versionRaw || '1');
   if (!version || version === 1) return name;
   return `${name}V${version}`;
 }
 
 async function resolvePortsDir(workspaceRoot) {
   const candidates = [
     path.resolve(workspaceRoot, '..', 'runtimes', 'ts', 'ports'),
     path.resolve(workspaceRoot, '..', '..', 'runtimes', 'ts', 'ports'),
     path.resolve(process.cwd(), 'runtimes', 'ts', 'ports')
   ];
   for (const candidate of candidates) {
     try {
       const stat = await fs.stat(candidate);
       if (stat.isDirectory()) return candidate;
     } catch {
       continue;
     }
   }
   return path.resolve(process.cwd(), 'runtimes', 'ts', 'ports');
 }
 
 async function buildPortHarness(manifests, workspaceRoot, portsDir, ee) {
   const entries = [];
   let harnessDir = null;
 
   async function ensureHarnessDir() {
     if (!harnessDir) {
       harnessDir = path.join(workspaceRoot, '.tm', 'port-checks');
       await fs.rm(harnessDir, { recursive: true, force: true }).catch(() => {});
       await fs.mkdir(harnessDir, { recursive: true });
     }
   }
 
   for (const [moduleId, data] of Object.entries(manifests)) {
     const { manifest, root } = data;
     const provides = manifest.provides || [];
     const portExports = manifest.port_exports || {};
     for (const port of provides) {
-      ee.emit('PORT_CHECK_START', { module: moduleId, port });
+      await ee.emit('PORT_CHECK_START', { module: moduleId, port });
       let binding = portExports[port];
       if (!binding) {
         const fallback = 'src/index.ts';
         try {
           await fs.access(path.join(root, fallback));
           binding = { file: fallback, export: 'default' };
-          ee.emit('GATES_WARN', { warn: 'port_exports_missing', module: moduleId, port });
+          await ee.emit('GATES_WARN', { code: 'WARN_PORT_EXPORTS_MISSING', module: moduleId, port });
         } catch {
-          ee.emit('PORT_CHECK_FAIL', { module: moduleId, port, error: 'port_export_not_found' });
-          throw new Error(`Port ${port} for ${moduleId} missing port_exports entry and fallback ${fallback} not found.`);
+          await ee.emit('PORT_CHECK_FAIL', { module: moduleId, port, error: 'port_export_not_found', code: 'E_PORT_CONFORMANCE' });
+          throw tmError('E_PORT_CONFORMANCE', `Port ${port} for ${moduleId} missing port_exports entry and fallback ${fallback} not found.`);
         }
       }
 
       const absFile = path.join(root, binding.file);
       try {
         await fs.access(absFile);
       } catch {
-        ee.emit('PORT_CHECK_FAIL', { module: moduleId, port, error: 'port_export_not_found' });
-        throw new Error(`Port ${port} for ${moduleId} references missing file ${binding.file}`);
+        await ee.emit('PORT_CHECK_FAIL', { module: moduleId, port, error: 'port_export_not_found', code: 'E_PORT_CONFORMANCE' });
+        throw tmError('E_PORT_CONFORMANCE', `Port ${port} for ${moduleId} references missing file ${binding.file}`);
       }
 
       await ensureHarnessDir();
       const safeModule = moduleId.replace(/[\\/]/g, '_');
       const safePort = port.replace(/[\\/]/g, '_');
       const harnessPath = path.join(harnessDir, `${safeModule}__${safePort}.ts`);
 
       const relativeImport = path.relative(harnessDir, absFile).replace(/\\/g, '/');
       const importSpecifier = relativeImport.startsWith('.') ? relativeImport : `./${relativeImport}`;
       const portsImportRelative = path.relative(harnessDir, path.join(portsDir, 'index.js')).replace(/\\/g, '/');
       const portsImport = portsImportRelative.startsWith('.') ? portsImportRelative : `./${portsImportRelative}`;
       const interfaceName = interfaceNameForPort(port);
       let importLines;
       let reference = 'portExport';
       if ((binding.export || '').toLowerCase() === 'default') {
         importLines = `import provider from '${importSpecifier}';\nconst ${reference} = provider;`;
       } else {
         importLines = `import { ${binding.export} as ${reference} } from '${importSpecifier}';`;
       }
       const harnessCode = `import type { ${interfaceName} } from '${portsImport}';\n${importLines}\nconst _check: ${interfaceName} = ${reference};\nexport {};\n`;
       await fs.writeFile(harnessPath, harnessCode);
       entries.push({ harnessPath, module: moduleId, port });
     }
   }
 
@@ -220,130 +472,137 @@ async function crossImportLint(modulesRoot) {
         const r = line.match(/require\(\s*['"]([^'"]+)['"]\s*\)/);
         const imp = m ? m[1] : (r ? r[1] : null);
         if (!imp) return;
         if (imp.startsWith('..')) {
           problems.push({ file: fp, line: idx+1, msg: `relative import escapes module root: ${imp}` });
         }
         if (imp.includes('modules/')) {
           const parts = imp.split('modules/');
           if (parts[1]) {
             const other = parts[1].split(/[\\/]/)[0];
             if (other && other !== modId) {
               problems.push({ file: fp, line: idx+1, msg: `imports sibling module '${other}'` });
             }
           }
         }
       });
     }
   }
   return problems;
 }
 
 program
   .command('schema-compile')
   .description('Compile all JSON Schemas to ensure they are valid (AJV 2020-12)')
   .action(async () => {
-    const files = ['module.schema.json','compose.schema.json','coverage.schema.json','report.schema.json'];
+    const files = ['module.schema.json','compose.schema.json','coverage.schema.json','report.schema.json','events.schema.json'];
     for (const f of files) {
       const schema = await loadJSON(path.join(specDir, f));
       const ajv = makeAjv();
       ajv.compile(schema);
       console.log(`✓ Compiled ${f}`);
     }
   });
 
 program
   .command('compose')
   .requiredOption('--compose <file>', 'Path to compose.json')
   .requiredOption('--modules-root <dir>', 'Root directory containing module folders (with module.json)')
   .option('--out <dir>', './winner', 'Output directory for winner artifacts')
+  .option('--explain', 'Print provider resolution details', false)
   .description('Validate compose plan and manifests; emit a minimal winner report (scaffold)')
   .action(async (opts) => {
     const compose = await validateFile('compose.schema.json', path.resolve(opts.compose));
     const modulesRoot = path.resolve(opts.modules_root || opts.modulesRoot);
 
     // Load and validate module manifests
     const moduleEntries = {};
     for (const m of compose.modules || []) {
       const mdir = path.join(modulesRoot, m.id);
       const mfile = path.join(mdir, 'module.json');
       const manifest = await validateFile('module.schema.json', mfile);
       moduleEntries[m.id] = { dir: mdir, manifest };
     }
 
     const manifestsById = Object.fromEntries(
       Object.entries(moduleEntries).map(([k, v]) => [k, v.manifest])
     );
     const reqProblems = verifyPortRequires(compose, manifestsById);
     if (reqProblems.length) {
-      throw new Error('Compose port requirements failed:\n' + reqProblems.join('\n'));
+      throw tmError('E_REQUIRE_UNSAT', 'Compose port requirements failed:\n' + reqProblems.join('\n'));
     }
 
     // Basic wiring checks
     const providesPort = (manifest, portName) => {
       const arr = manifest.provides || [];
       return arr.some(p => (p.split('@')[0] === portName));
     };
 
     for (const w of (compose.wiring || [])) {
       const [fromName, fromPort] = w.from.split(':');
       const [toName, toPort] = w.to.split(':');
       if (!fromName || !fromPort || !toName || !toPort) {
-        throw new Error(`Invalid wiring entry: ${JSON.stringify(w)}`);
+        throw tmError('E_COMPOSE', `Invalid wiring entry: ${JSON.stringify(w)}`);
       }
       if (fromName !== 'orchestrator') {
         const ent = moduleEntries[fromName];
-        if (!ent) throw new Error(`Wiring 'from' references unknown module: ${fromName}`);
+        if (!ent) throw tmError('E_COMPOSE', `Wiring 'from' references unknown module: ${fromName}`);
         if (!providesPort(ent.manifest, fromPort)) {
-          throw new Error(`Module ${fromName} does not provide port ${fromPort}`);
+          throw tmError('E_COMPOSE', `Module ${fromName} does not provide port ${fromPort}`);
         }
       }
     }
 
+    const { explanations } = analyzeProviders(compose, moduleEntries);
+
     // Emit a minimal winner report
     const outDir = path.resolve(opts.out || './winner');
     await fs.mkdir(outDir, { recursive: true });
     const winnerReport = {
       context: {
         run_id: compose.run_id || new Date().toISOString(),
         composer: 'tm (scaffold)',
         generated_at: new Date().toISOString()
       },
       bill_of_materials: (compose.modules || []).map(m => ({
         id: m.id, version: m.version || '0.0.0'
       })),
       wiring: compose.wiring || [],
       glue: compose.glue || [],
       constraints: compose.constraints || [],
       notes: [
         "This is a scaffold winner report generated without building/linking.",
         "Use the full Composer to assemble code and run gates in shipping mode."
       ]
     };
     await fs.writeFile(path.join(outDir, 'report.json'), JSON.stringify(winnerReport, null, 2));
     await fs.writeFile(path.join(outDir, 'README.md'), '# Winner (scaffold)\n\nGenerated by `tm compose`.');
     console.log(`✓ Wrote ${path.join(outDir, 'report.json')}`);
+
+    if (opts.explain) {
+      console.log(JSON.stringify(explanations, null, 2));
+    }
   });
 
 program
   .command('meta')
   .requiredOption('--coverage <file>', 'Path to coverage.json')
   .option('--out <file>', './compose.greedy.json', 'Output compose file')
   .description('Greedy set-cover with simple risk/evidence scoring')
   .action(async (opts) => {
     const cov = await validateFile('coverage.schema.json', path.resolve(opts.coverage));
     const weights = cov.weights || {};
     const goals = new Set(cov.goals || []);
 
     // Build module->goal map and attach risk/evidence
     const meta = {};
     for (const p of (cov.provides || [])) {
       const mod = p.module; // e.g., "git.diff.core@var4"
       if (!meta[mod]) meta[mod] = { goals: new Set(), risk: 0.5, ev: 0.5 };
       for (const g of (p.covers || [])) meta[mod].goals.add(g);
       if (typeof p.risk === 'number') meta[mod].risk = p.risk;
       if (typeof p.evidence_strength === 'number') meta[mod].ev = p.evidence_strength;
     }
 
     const covered = new Set();
     const selected = [];
 
@@ -368,194 +627,220 @@ program
       selected.push(best);
       for (const g of meta[best].goals) covered.add(g);
       delete meta[best];
       if ([...goals].every(g => covered.has(g))) break;
     }
 
     const modulesList = selected.map(id => ({ id: id.split('@')[0], version: "0.1.0" }));
 
     const compose = {
       run_id: new Date().toISOString(),
       modules: modulesList,
       wiring: [],
       glue: [],
       constraints: ["no-cross-imports", "ports-only-coupling"]
     };
     await fs.writeFile(path.resolve(opts.out || './compose.greedy.json'), JSON.stringify(compose, null, 2));
     console.log(`✓ Wrote ${opts.out || './compose.greedy.json'} with ${modulesList.length} modules`);
   });
 
 program
   .command('gates')
   .argument('<mode>', 'conceptual|shipping')
   .requiredOption('--compose <file>', 'Path to compose.json')
   .requiredOption('--modules-root <dir>', 'Root dir of modules')
   .option('--emit-events', 'Emit line-delimited JSON events', false)
+  .option('--events-out <file>', 'Write events to file (NDJSON)')
+  .option('--events-truncate', 'Truncate events output file before writing', false)
+  .option('--strict-events', 'Validate events against tm-events@1 schema (fail fast)', false)
   .option('--hook-cmd <cmd>', 'Run a hook that receives a summary JSON on stdin')
   .option('--timeout-ms <n>', 'Per-test timeout (ms)', '60000')
   .description('Run conceptual / shipping gates')
   .action(async (mode, opts) => {
-    const compose = await validateFile('compose.schema.json', path.resolve(opts.compose));
+    const composePath = path.resolve(opts.compose);
+    const compose = await validateFile('compose.schema.json', composePath);
+    const composeHash = crypto.createHash('sha256').update(await fs.readFile(composePath)).digest('hex');
     const modulesRoot = path.resolve(opts.modules_root || opts.modulesRoot);
     const manifests = {};
-    const ee = makeEventEmitter(opts);
-    const gateStart = Date.now();
+    const runId = compose.run_id || new Date().toISOString();
     const moduleIds = (compose.modules || []).map(m => m.id);
+    const ee = await makeEventEmitter({
+      emitEvents: opts.emitEvents,
+      eventsOut: opts.eventsOut ? path.resolve(opts.eventsOut) : null,
+      eventsTruncate: opts.eventsTruncate,
+      strictEvents: opts.strictEvents,
+      context: { run_id: runId, mode, compose_sha256: composeHash }
+    });
+    const gateStart = Date.now();
     const summary = {
-      run_id: compose.run_id || new Date().toISOString(),
+      run_id: runId,
       mode,
       modules: moduleIds,
       results: { passed: 0, failed: 0 }
     };
-    ee.emit('GATES_START', { mode, compose: opts.compose, run_id: compose.run_id || null });
     let successMessage = '';
+    let failureCode = null;
 
     try {
+      await ee.emit('GATES_START', { compose_path: composePath, modules_total: moduleIds.length });
       // Shared checks
       for (const m of compose.modules || []) {
         const mroot = path.join(modulesRoot, m.id);
         const fp = path.join(mroot, 'module.json');
         const manifest = await validateFile('module.schema.json', fp);
         manifests[m.id] = { manifest, root: mroot };
         if (!Array.isArray(manifest.evidence) || manifest.evidence.length === 0) {
-          throw new Error(`Gate failure: ${m.id} has no evidence bindings.`);
+          throw tmError('E_REQUIRE_UNSAT', `Gate failure: ${m.id} has no evidence bindings.`);
         }
         if (!Array.isArray(manifest.tests) || manifest.tests.length === 0) {
-          throw new Error(`Gate failure: ${m.id} defines no tests.`);
+          throw tmError('E_REQUIRE_UNSAT', `Gate failure: ${m.id} defines no tests.`);
         }
         if (!Array.isArray(manifest.invariants) || manifest.invariants.length === 0) {
-          throw new Error(`Gate failure: ${m.id} defines no invariants.`);
+          throw tmError('E_REQUIRE_UNSAT', `Gate failure: ${m.id} defines no invariants.`);
         }
       }
 
       // Cross-import lint (ESLint preferred, regex fallback)
       let ranEslint = false;
+      const lintStart = Date.now();
+      await ee.emit('LINT_START', { lint_tool: 'eslint' });
       try {
         const { errorCount, diagnostics } = await collectCrossImportDiagnostics([modulesRoot]);
         ranEslint = true;
         if (errorCount > 0) {
           const formatted = diagnostics.slice(0, 20).map(d => {
             const rel = path.relative(process.cwd(), d.file);
             return `${rel}:${d.line}:${d.column} ${d.message}`;
           }).join('\n');
           const first = diagnostics[0];
-          ee.emit('GATES_FAIL', {
-            mode,
-            error: 'lint_failed',
+          failureCode = 'E_LINT';
+          await ee.emit('LINT_FAIL', {
+            lint_tool: 'eslint',
+            code: 'E_LINT',
+            message: first?.message,
             file: first ? path.relative(process.cwd(), first.file) : undefined,
             line: first?.line,
-            message: first?.message
+            dur_ms: Date.now() - lintStart
           });
-          throw new Error('ESLint cross-module check failed:\n' + formatted);
+          throw tmError('E_LINT', 'ESLint cross-module check failed:\n' + formatted);
         }
+        await ee.emit('LINT_PASS', { lint_tool: 'eslint', dur_ms: Date.now() - lintStart });
       } catch (err) {
         if (!ranEslint && err && (err.code === 'ERR_MODULE_NOT_FOUND' || (typeof err.message === 'string' && err.message.includes("Cannot find module 'eslint'")))) {
-          ee.emit('GATES_WARN', { warn: 'eslint_unavailable' });
+          await ee.emit('GATES_WARN', { code: 'WARN_ESLINT_UNAVAILABLE', message: 'eslint not available; falling back to regex lint' });
+          const fallbackStart = Date.now();
+          await ee.emit('LINT_START', { lint_tool: 'fallback-regex' });
           const lint = await crossImportLint(modulesRoot);
           if (lint.length) {
             const formatted = lint.slice(0, 20).map(entry => {
               const rel = path.relative(process.cwd(), entry.file);
               return `${rel}:${entry.line} ${entry.msg}`;
             }).join('\n');
-            ee.emit('GATES_FAIL', {
-              mode,
-              error: 'lint_failed',
+            failureCode = 'E_LINT';
+            await ee.emit('LINT_FAIL', {
+              lint_tool: 'fallback-regex',
+              code: 'E_LINT',
+              message: lint[0].msg,
               file: path.relative(process.cwd(), lint[0].file),
               line: lint[0].line,
-              message: lint[0].msg
+              dur_ms: Date.now() - fallbackStart
             });
-            throw new Error('Cross-module import violations:\n' + formatted);
+            throw tmError('E_LINT', 'Cross-module import violations:\n' + formatted);
           }
+          await ee.emit('LINT_PASS', { lint_tool: 'fallback-regex', dur_ms: Date.now() - fallbackStart });
         } else if (!ranEslint) {
           throw err instanceof Error ? err : new Error(String(err));
         } else {
           throw err instanceof Error ? err : new Error(String(err));
         }
       }
 
       if (mode === 'conceptual') {
         successMessage = '✓ Conceptual gates passed.';
       } else {
         const timeoutMs = Number(opts.timeoutMs ?? 60_000);
         if (!Number.isFinite(timeoutMs) || timeoutMs <= 0) {
-          throw new Error('Gate failure: invalid --timeout-ms value.');
+          throw tmError('E_REQUIRE_UNSAT', 'Gate failure: invalid --timeout-ms value.');
         }
 
         const reqProblems = verifyPortRequires(
           compose,
           Object.fromEntries(Object.entries(manifests).map(([k, v]) => [k, v.manifest]))
         );
         if (reqProblems.length) {
-          throw new Error('Gate failure: port requirements unmet:\n' + reqProblems.join('\n'));
+          failureCode = 'E_REQUIRE_UNSAT';
+          throw tmError('E_REQUIRE_UNSAT', 'Gate failure: port requirements unmet:\n' + reqProblems.join('\n'));
         }
 
         if (!(compose.wiring && compose.wiring.length) && !(compose.constraints && compose.constraints.length)) {
-          throw new Error('Gate failure: shipping mode requires non-empty wiring or constraints.');
+          throw tmError('E_REQUIRE_UNSAT', 'Gate failure: shipping mode requires non-empty wiring or constraints.');
         }
 
         let total = 0;
         let passed = 0;
         for (const m of compose.modules || []) {
           const { manifest, root } = manifests[m.id];
           for (const t of manifest.tests || []) {
             if (typeof t !== 'string') {
-              throw new Error(`Test entry for ${m.id} is not a string: ${JSON.stringify(t)}`);
+              throw tmError('E_REQUIRE_UNSAT', `Test entry for ${m.id} is not a string: ${JSON.stringify(t)}`);
             }
             total += 1;
             const testStart = Date.now();
-            ee.emit('TEST_START', { module: m.id, test: t });
+            await ee.emit('TEST_START', { module: m.id, test: t });
             try {
               if (t.startsWith('script:')) {
                 const scriptRel = t.replace(/^script:/, '').trim();
-                if (!scriptRel) throw new Error('Script entry missing path');
+                if (!scriptRel) throw tmError('E_REQUIRE_UNSAT', 'Script entry missing path');
                 const scriptAbs = path.join(root, scriptRel);
                 await runCmd(process.execPath, [scriptAbs], { cwd: root, timeoutMs });
               } else if (t.endsWith('.json')) {
                 const runner = path.join(root, 'tests', 'runner.mjs');
                 await fs.access(runner);
                 const specPath = path.join(root, t);
                 await runCmd(
                   process.execPath,
                   [runner, '--spec', specPath, '--moduleRoot', root],
                   { cwd: root, timeoutMs }
                 );
               } else {
-                throw new Error(`Unknown test entry: ${t}`);
+                throw tmError('E_REQUIRE_UNSAT', `Unknown test entry: ${t}`);
               }
               const dur = Date.now() - testStart;
               passed += 1;
-              ee.emit('TEST_PASS', { module: m.id, test: t, dur_ms: dur });
+              await ee.emit('TEST_PASS', { module: m.id, test: t, dur_ms: dur });
             } catch (e) {
               const dur = Date.now() - testStart;
               const errMsg = e instanceof Error ? e.message : String(e);
-              ee.emit('TEST_FAIL', { module: m.id, test: t, dur_ms: dur, error: errMsg });
+              failureCode = 'E_TEST';
+              await ee.emit('TEST_FAIL', { module: m.id, test: t, dur_ms: dur, error: errMsg, code: 'E_TEST' });
               summary.results = { passed, failed: total - passed };
-              throw new Error(`Test failed for ${m.id} (${t}): ${errMsg}`);
+              throw tmError('E_TEST', `Test failed for ${m.id} (${t}): ${errMsg}`);
             }
           }
         }
 
+        summary.results = { passed, failed: 0 };
         const workspaceRoot = path.resolve(modulesRoot, '..');
         const portsDir = await resolvePortsDir(workspaceRoot);
         const portHarness = await buildPortHarness(manifests, workspaceRoot, portsDir, ee);
         const dirsToCheck = [modulesRoot];
         const glueDir = path.join(workspaceRoot, 'glue');
         try {
           const glueStat = await fs.stat(glueDir);
           if (glueStat.isDirectory()) dirsToCheck.push(glueDir);
         } catch {}
 
         const includeDirs = [...dirsToCheck];
         if (portHarness.harnessDir) includeDirs.push(portHarness.harnessDir);
         includeDirs.push(portsDir);
 
         let tsFiles = [];
         for (const dir of dirsToCheck) {
           const files = await listFilesRec(dir, ['.ts', '.tsx']);
           tsFiles = tsFiles.concat(files);
         }
 
         const mustTypeCheck = tsFiles.length > 0 || (portHarness.entries && portHarness.entries.length > 0);
 
         if (mustTypeCheck) {
           const tmDir = path.join(workspaceRoot, '.tm');
           await fs.mkdir(tmDir, { recursive: true });
@@ -567,125 +852,129 @@ program
           });
           const tsConfig = {
             compilerOptions: {
               module: "NodeNext",
               moduleResolution: "NodeNext",
               target: "ES2022",
               strict: true,
               skipLibCheck: true,
               allowImportingTsExtensions: true
             },
             include: includePaths
           };
           await fs.writeFile(tsProjectPath, JSON.stringify(tsConfig, null, 2));
 
           const requireForTs = createRequire(import.meta.url);
           let tscBin;
           try {
             const tsPackagePath = requireForTs.resolve('typescript/package.json');
             const tsPackage = requireForTs(tsPackagePath);
             const binRelative = tsPackage && tsPackage.bin && tsPackage.bin.tsc ? tsPackage.bin.tsc : 'bin/tsc';
             tscBin = path.join(path.dirname(tsPackagePath), binRelative);
           } catch {
             tscBin = null;
           }
           if (!tscBin) {
-            throw new Error('TypeScript compiler not found. Install with `npm i -D typescript`.');
+            throw tmError('E_TSC', 'TypeScript compiler not found. Install with `npm i -D typescript`.');
           }
           try {
             await fs.access(tscBin);
           } catch {
-            throw new Error('TypeScript compiler not found. Install with `npm i -D typescript`.');
+            throw tmError('E_TSC', 'TypeScript compiler not found. Install with `npm i -D typescript`.');
           }
 
-          ee.emit('TSC_START', { mode });
+          await ee.emit('TSC_START', { artifact: path.relative(process.cwd(), tscLogPath) });
           const start = Date.now();
           const child = spawn(process.execPath, [tscBin, '--noEmit', '--project', tsProjectPath], {
             cwd: workspaceRoot,
             shell: false
           });
           let stdout = '';
           let stderr = '';
           child.stdout.on('data', d => { stdout += d; });
           child.stderr.on('data', d => { stderr += d; });
           const exitCode = await new Promise((resolve, reject) => {
             child.on('error', reject);
             child.on('exit', code => resolve(code));
           });
           const duration = Date.now() - start;
           const combined = `${stdout}${stderr}`;
           await fs.writeFile(tscLogPath, combined);
           if (exitCode !== 0) {
             const lines = combined.split(/\r?\n/).filter(Boolean).slice(0, 10);
-            ee.emit('TSC_FAIL', { mode, dur_ms: duration });
+            failureCode = 'E_TSC';
+            await ee.emit('TSC_FAIL', { dur_ms: duration, artifact: path.relative(process.cwd(), tscLogPath), code: 'E_TSC' });
             if (portHarness.entries?.length) {
               const firstLine = lines[0] || '';
               const match = portHarness.entries.find(entry => firstLine.includes(path.basename(entry.harnessPath)) || combined.includes(entry.harnessPath));
               if (match) {
-                ee.emit('PORT_CHECK_FAIL', { module: match.module, port: match.port, error: 'port_conformance_failed' });
+                await ee.emit('PORT_CHECK_FAIL', { module: match.module, port: match.port, error: 'port_conformance_failed', code: 'E_PORT_CONFORMANCE' });
               }
             }
-            throw new Error(`TypeScript check failed:\n${lines.join('\n')}\nSee full log at ${tscLogPath}`);
+            throw tmError('E_TSC', `TypeScript check failed:\n${lines.join('\n')}\nSee full log at ${tscLogPath}`);
           } else {
-            ee.emit('TSC_PASS', { mode, dur_ms: duration });
+            await ee.emit('TSC_PASS', { dur_ms: duration, artifact: path.relative(process.cwd(), tscLogPath) });
             if (portHarness.entries?.length) {
               for (const entry of portHarness.entries) {
-                ee.emit('PORT_CHECK_PASS', { module: entry.module, port: entry.port });
+                await ee.emit('PORT_CHECK_PASS', { module: entry.module, port: entry.port });
               }
             }
           }
         }
 
-        summary.results = { passed, failed: 0 };
         successMessage = `✓ Shipping tests passed (${passed}/${total}).`;
       }
       summary.duration_ms = Date.now() - gateStart;
 
       if (opts.hookCmd) {
         await new Promise((resolve, reject) => {
           const child = spawn(opts.hookCmd, {
             shell: true,
             stdio: ['pipe', 'inherit', 'inherit']
           });
           child.on('error', reject);
           child.on('exit', code => {
             if (code === 0) resolve();
-            else reject(new Error(`Hook exited with code ${code}`));
+            else reject(tmError('E_HOOK', `Hook exited with code ${code}`));
           });
           child.stdin.write(JSON.stringify(summary));
           child.stdin.end();
         });
       }
 
-      ee.emit('GATES_PASS', { mode, ...summary.results });
+      await ee.emit('GATES_PASS', { passed: summary.results.passed, failed: summary.results.failed, dur_ms: summary.duration_ms });
       if (successMessage) ee.info(successMessage);
     } catch (err) {
       summary.duration_ms = Date.now() - gateStart;
       const message = err instanceof Error ? err.message : String(err);
       summary.error = message;
-      ee.emit('GATES_FAIL', { mode, error: message, ...summary.results });
+      const code = err && typeof err === 'object' && 'code' in err && err.code ? err.code : (failureCode || 'E_UNKNOWN');
+      summary.code = code;
+      await ee.emit('GATES_FAIL', { code, message, passed: summary.results.passed, failed: summary.results.failed, dur_ms: summary.duration_ms });
       throw err instanceof Error ? err : new Error(message);
+    } finally {
+      await ee.close();
     }
   });
 
 program
   .command('module')
   .requiredOption('--new <id>', 'Module id, e.g. git.diff.core')
   .option('--root <dir>', 'Modules root directory', 'modules')
   .description('Create a new module scaffold that passes schema validation')
   .action(async (opts) => {
     const id = opts.new;
     if (!/^[a-z][a-z0-9_.-]+$/.test(id)) {
       throw new Error('Invalid module id. Use lowercase letters, digits, dot/underscore/dash.');
     }
     const dir = path.resolve(opts.root, id);
     await fs.mkdir(path.join(dir, 'src'), { recursive: true });
     await fs.mkdir(path.join(dir, 'tests'), { recursive: true });
 
     const manifest = {
       id,
       version: "0.1.0",
       summary: "New module",
       provides: ["ExamplePort@1"],
       requires: [],
       inputs: {},
       outputs: {},
